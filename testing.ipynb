{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d3eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading_times: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 36, 40, 55]\n",
      "publications: ['Towards Data Science', 'UX Collective', 'The Startup', 'The Writing Cooperative', 'Data Driven Investor', 'Better Marketing', 'Better Humans']\n",
      "\n",
      "0 The Startup               2\n",
      "\n",
      "1 Towards Data Science      3\n",
      "1 UX Collective             1\n",
      "1 The Startup               7\n",
      "1 The Writing Cooperative   1\n",
      "1 Data Driven Investor      2\n",
      "\n",
      "2 Towards Data Science      22\n",
      "2 UX Collective             19\n",
      "2 The Startup               72\n",
      "2 The Writing Cooperative   12\n",
      "2 Data Driven Investor      40\n",
      "2 Better Marketing          2\n",
      "2 Better Humans             1\n",
      "\n",
      "3 Towards Data Science      87\n",
      "3 UX Collective             75\n",
      "3 The Startup               340\n",
      "3 The Writing Cooperative   87\n",
      "3 Data Driven Investor      141\n",
      "3 Better Marketing          17\n",
      "3 Better Humans             2\n",
      "\n",
      "4 Towards Data Science      162\n",
      "4 UX Collective             86\n",
      "4 The Startup               583\n",
      "4 The Writing Cooperative   106\n",
      "4 Data Driven Investor      198\n",
      "4 Better Marketing          44\n",
      "\n",
      "5 Towards Data Science      255\n",
      "5 UX Collective             105\n",
      "5 The Startup               649\n",
      "5 The Writing Cooperative   72\n",
      "5 Data Driven Investor      131\n",
      "5 Better Marketing          58\n",
      "5 Better Humans             2\n",
      "\n",
      "6 Towards Data Science      225\n",
      "6 UX Collective             84\n",
      "6 The Startup               466\n",
      "6 The Writing Cooperative   55\n",
      "6 Data Driven Investor      97\n",
      "6 Better Marketing          38\n",
      "\n",
      "7 Towards Data Science      186\n",
      "7 UX Collective             62\n",
      "7 The Startup               333\n",
      "7 The Writing Cooperative   27\n",
      "7 Data Driven Investor      60\n",
      "7 Better Marketing          26\n",
      "\n",
      "8 Towards Data Science      132\n",
      "8 UX Collective             43\n",
      "8 The Startup               190\n",
      "8 The Writing Cooperative   16\n",
      "8 Data Driven Investor      38\n",
      "8 Better Marketing          16\n",
      "8 Better Humans             3\n",
      "\n",
      "9 Towards Data Science      103\n",
      "9 UX Collective             30\n",
      "9 The Startup               131\n",
      "9 The Writing Cooperative   12\n",
      "9 Data Driven Investor      28\n",
      "9 Better Marketing          9\n",
      "9 Better Humans             2\n",
      "\n",
      "10 Towards Data Science      79\n",
      "10 UX Collective             14\n",
      "10 The Startup               80\n",
      "10 The Writing Cooperative   3\n",
      "10 Data Driven Investor      15\n",
      "10 Better Marketing          12\n",
      "10 Better Humans             1\n",
      "\n",
      "11 Towards Data Science      44\n",
      "11 UX Collective             7\n",
      "11 The Startup               61\n",
      "11 The Writing Cooperative   5\n",
      "11 Data Driven Investor      5\n",
      "11 Better Marketing          5\n",
      "11 Better Humans             2\n",
      "\n",
      "12 Towards Data Science      40\n",
      "12 UX Collective             7\n",
      "12 The Startup               29\n",
      "12 The Writing Cooperative   5\n",
      "12 Data Driven Investor      7\n",
      "12 Better Marketing          4\n",
      "12 Better Humans             1\n",
      "\n",
      "13 Towards Data Science      34\n",
      "13 UX Collective             8\n",
      "13 The Startup               24\n",
      "13 The Writing Cooperative   1\n",
      "13 Data Driven Investor      4\n",
      "13 Better Marketing          3\n",
      "13 Better Humans             3\n",
      "\n",
      "14 Towards Data Science      18\n",
      "14 UX Collective             6\n",
      "14 The Startup               14\n",
      "14 Data Driven Investor      3\n",
      "14 Better Marketing          2\n",
      "14 Better Humans             2\n",
      "\n",
      "15 Towards Data Science      14\n",
      "15 UX Collective             2\n",
      "15 The Startup               14\n",
      "15 Data Driven Investor      4\n",
      "15 Better Marketing          1\n",
      "15 Better Humans             2\n",
      "\n",
      "16 Towards Data Science      14\n",
      "16 UX Collective             2\n",
      "16 The Startup               15\n",
      "16 Better Marketing          1\n",
      "16 Better Humans             1\n",
      "\n",
      "17 Towards Data Science      9\n",
      "17 UX Collective             1\n",
      "17 The Startup               9\n",
      "17 Better Humans             2\n",
      "\n",
      "18 Towards Data Science      9\n",
      "18 The Startup               5\n",
      "18 The Writing Cooperative   1\n",
      "18 Data Driven Investor      1\n",
      "\n",
      "19 Towards Data Science      5\n",
      "19 UX Collective             1\n",
      "19 The Startup               4\n",
      "19 Data Driven Investor      1\n",
      "19 Better Marketing          1\n",
      "\n",
      "20 Towards Data Science      4\n",
      "20 UX Collective             1\n",
      "20 The Startup               2\n",
      "20 Better Marketing          1\n",
      "\n",
      "21 Towards Data Science      3\n",
      "21 The Startup               3\n",
      "\n",
      "22 Towards Data Science      4\n",
      "22 The Startup               6\n",
      "22 Data Driven Investor      2\n",
      "\n",
      "23 Towards Data Science      2\n",
      "23 Better Humans             1\n",
      "\n",
      "24 Towards Data Science      1\n",
      "24 Better Marketing          1\n",
      "24 Better Humans             1\n",
      "\n",
      "25 Towards Data Science      2\n",
      "25 The Startup               1\n",
      "\n",
      "26 Towards Data Science      1\n",
      "\n",
      "27 Data Driven Investor      1\n",
      "27 Better Marketing          1\n",
      "\n",
      "31 Towards Data Science      1\n",
      "31 The Startup               1\n",
      "\n",
      "32 Towards Data Science      1\n",
      "\n",
      "33 Towards Data Science      1\n",
      "\n",
      "36 Better Humans             1\n",
      "\n",
      "40 Better Humans             1\n",
      "\n",
      "55 UX Collective             1\n",
      "\n",
      "(649, 11)\n",
      "(649, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#Sentences are encoded by calling model.encode()\n",
    "\n",
    "df = pd.read_csv ('medium_data.csv')\n",
    "# https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset\n",
    "\n",
    "# combine title and subtitle into full_title\n",
    "df['full_title'] = df.apply(lambda row: row['title'] if pd.isnull(row['subtitle']) else row['title'] + ': ' + row['subtitle'], axis=1)\n",
    "\n",
    "# find how many of each article there are with the same publisher, and reading time\n",
    "reading_times = sorted(df['reading_time'].unique())\n",
    "publications = list(df['publication'].unique())\n",
    "print(\"reading_times:\", reading_times)\n",
    "print(\"publications:\", publications)\n",
    "print()\n",
    "\n",
    "for t in reading_times:\n",
    "    for p in publications:\n",
    "        articles = df[(df['reading_time'] == t) & (df['publication'] == p)]\n",
    "        shape = articles.shape\n",
    "        if shape[0] != 0:\n",
    "            print(t, p, ' '*(24-len(p)), shape[0])\n",
    "    print()\n",
    "    \n",
    "# subset rows based on biggest group\n",
    "df = df[(df['reading_time'] == 5) & (df['publication'] == 'The Startup')]\n",
    "print(df.shape)\n",
    "\n",
    "# subset df to only include relevant columns\n",
    "y_col = 'claps'\n",
    "x_col = 'full_title'\n",
    "df = df[['id', x_col, y_col]]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98962754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 10\n",
    "test_size = 5\n",
    "\n",
    "test_df = df[train_size: train_size + test_size]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "df = df[0:train_size]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(test_df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37940c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = len(df.index)\n",
    "test_df_rows = len(test_df.index)\n",
    "distances = [[None for _ in range(df_rows)] for _ in range(test_df_rows)]\n",
    "\n",
    "k = 3 # or whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7430c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances between test values and train values\n",
    "for i in range(test_df_rows):\n",
    "    for j in range(df_rows):\n",
    "        emb1 = model.encode(test_df[x_col][i])\n",
    "        emb2 = model.encode(df[x_col][j])\n",
    "        cos_sim = abs(float(util.cos_sim(emb1, emb2)))\n",
    "        \n",
    "        # store training data index along with cos_sim\n",
    "        distances[i][j] = (j, cos_sim, df[y_col][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1992b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013 11700, 0.067 1800, 0.025 1300, 0.009 148, 0.039 212, 0.068 235, 0.009 378, 0.027 9, 0.022 129, 0.032 70, \n",
      "0.238 11700, 0.048 1800, 0.026 1300, 0.003 148, 0.299 212, 0.167 235, 0.175 378, 0.149 9, 0.256 129, 0.177 70, \n",
      "0.224 11700, 0.058 1800, 0.011 1300, 0.013 148, 0.228 212, 0.127 235, 0.239 378, 0.071 9, 0.236 129, 0.207 70, \n",
      "0.079 11700, 0.014 1800, 0.131 1300, 0.039 148, 0.070 212, 0.162 235, 0.000 378, 0.260 9, 0.096 129, 0.078 70, \n",
      "0.119 11700, 0.009 1800, 0.139 1300, 0.079 148, 0.123 212, 0.021 235, 0.051 378, 0.136 9, 0.113 129, 0.023 70, \n"
     ]
    }
   ],
   "source": [
    "# print nicely formatted distance values\n",
    "for row in distances:\n",
    "    for n in row:\n",
    "        if n is None:\n",
    "            print('None  ', end='')\n",
    "        else:\n",
    "            print('%.3f'%(n[1]) + ' ' + str(n[2]) + ', ', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a3a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get k nearest neighbors for each testing data point\n",
    "knn_list = [None for _ in range(test_df_rows)]\n",
    "\n",
    "for (i, tup) in enumerate(distances):\n",
    "    sort_dist = sorted(tup, key=lambda x: x[1], reverse = True) # sort by cosine similarity\n",
    "    knn = sort_dist[:k]\n",
    "    knn_list[i] = knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17892257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 0.068   235,    1: 0.067  1800,    4: 0.039   212,    \n",
      "4: 0.299   212,    8: 0.256   129,    0: 0.238 11700,    \n",
      "6: 0.239   378,    8: 0.236   129,    4: 0.228   212,    \n",
      "7: 0.260     9,    5: 0.162   235,    2: 0.131  1300,    \n",
      "2: 0.139  1300,    7: 0.136     9,    4: 0.123   212,    \n"
     ]
    }
   ],
   "source": [
    "# print nicely formatted knn list\n",
    "for row in knn_list:\n",
    "    for n in row:\n",
    "        if n is None:\n",
    "            print('None  ', end='')\n",
    "        else:\n",
    "            print(str(n[0]) + ': ' + '%.3f'%(n[1]) + ' ' + str(n[2]).rjust(5) + ',    ', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6daa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each test data point, get average claps for its k nearest neighbors\n",
    "expected_claps = [None for _ in range(test_df_rows)]\n",
    "for i in range(test_df_rows):\n",
    "    sum_claps = 0\n",
    "    for j in range(k):\n",
    "        claps = knn_list[i][j][2]\n",
    "        sum_claps += claps\n",
    "    expected_claps[i] = sum_claps / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ba9502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[749.0, 4013.6666666666665, 239.66666666666666, 514.6666666666666, 507.0]\n"
     ]
    }
   ],
   "source": [
    "print(expected_claps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
